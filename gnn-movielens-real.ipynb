{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom networkx.algorithms import bipartite\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_add_pool\nfrom torch_geometric.data import Data, DataLoader\nfrom collections import defaultdict\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2023-10-06T15:45:10.167115Z","iopub.execute_input":"2023-10-06T15:45:10.168343Z","iopub.status.idle":"2023-10-06T15:45:10.201221Z","shell.execute_reply.started":"2023-10-06T15:45:10.168291Z","shell.execute_reply":"2023-10-06T15:45:10.199966Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCNConv, global_add_pool\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data, DataLoader\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"],"ename":"ModuleNotFoundError","evalue":"No module named 'torch_geometric'","output_type":"error"}]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/movielens-20m-dataset/rating.csv')\ndata = data.iloc[:10000]\nmovies_df = pd.read_csv(\"/kaggle/input/movielens-20m-dataset/movie.csv\")\ntags_df = pd.read_csv(\"/kaggle/input/movielens-20m-dataset/tag.csv\")\n\ntrain_data = data.copy()\ntest_data = pd.DataFrame()\n\nmovie_num_user_rated_counts = train_data['movieId'].value_counts()\n# Create a list of movie IDs with 50 or more ratings\npopular_movies = movie_num_user_rated_counts[movie_num_user_rated_counts >= 10].index.tolist()\n# Filter the DataFrame to keep only the rows with movies that meet the threshold\ntrain_data = train_data[train_data['movieId'].isin(popular_movies)]\n\nfor user_id in train_data['userId'].unique():\n    user_ratings = train_data[train_data['userId'] == user_id]\n    \n    if len(user_ratings) > 1:\n        test_rating = user_ratings.sample()\n        test_data = pd.concat([test_data, test_rating])\n        train_data.drop(test_rating.index, inplace=True)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-06T15:42:46.240472Z","iopub.status.idle":"2023-10-06T15:42:46.240843Z","shell.execute_reply.started":"2023-10-06T15:42:46.240689Z","shell.execute_reply":"2023-10-06T15:42:46.240704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef makeGraph(ratings_df):\n    G = nx.Graph()\n\n    # 2. Adding nodes and edges\n    # Add user nodes\n    for user_id in ratings_df['userId'].unique():\n        G.add_node(user_id, bipartite=0)  # Add user node with a bipartite attribute of 0\n\n    # Add movie nodes with title and genres as attributes\n    for _, row in movies_df.iterrows():\n        movie_id = 'm_' + str(row['movieId'])\n        G.add_node(movie_id, bipartite=1, title=row['title'], genres=row['genres'].split('|'))\n\n    # Add edges based on ratings with rating and timestamp as attributes\n    for _, row in ratings_df.iterrows():\n        user_id = row['userId']\n        movie_id = 'm_' + str(row['movieId'])\n        G.add_edge(user_id, movie_id, rating=row['rating'], timestamp=row['timestamp'])\n\n    # Add tag data as an attribute to the movie nodes\n    for _, row in tags_df.iterrows():\n        movie_id = 'm_' + str(row['movieId'])\n        if 'tags' not in G.nodes[movie_id]:\n            G.nodes[movie_id]['tags'] = []\n        G.nodes[movie_id]['tags'].append({'tag': row['tag'], 'timestamp': row['timestamp'], 'userId': row['userId']})\n\n    # Ensure the graph is bipartite\n    assert bipartite.is_bipartite(G)\n    return G\nG = makeGraph(train_data)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-06T15:42:46.241994Z","iopub.status.idle":"2023-10-06T15:42:46.242346Z","shell.execute_reply.started":"2023-10-06T15:42:46.242186Z","shell.execute_reply":"2023-10-06T15:42:46.242202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_graph(G):\n    # Create encoders\n    user_encoder = LabelEncoder()\n    movie_encoder = LabelEncoder()\n    genre_encoder = LabelEncoder()\n    tag_encoder = LabelEncoder()\n\n    # Collect data for encoding\n    users = [node for node, data in G.nodes(data=True) if data['bipartite'] == 0]\n    movies = [data['title'] for node, data in G.nodes(data=True) if data['bipartite'] == 1]\n    genres = [genre for node, data in G.nodes(data=True) if data['bipartite'] == 1 for genre in data['genres']]\n    tags = [tag_data['tag'] for node, data in G.nodes(data=True) if 'tags' in data for tag_data in data['tags']]\n\n    # Fit encoders\n    user_encoder.fit(users)\n    movie_encoder.fit(movies)\n    genre_encoder.fit(genres)\n    tag_encoder.fit(tags)\n\n    # Encode user nodes\n    for user in users:\n        encoded_user = user_encoder.transform([user])[0]\n        G = nx.relabel_nodes(G, {user: encoded_user})\n\n    # Encode movie nodes and their attributes\n    for node, data in list(G.nodes(data=True)):\n        if data['bipartite'] == 1:\n            encoded_movie = movie_encoder.transform([data['title']])[0]\n            G = nx.relabel_nodes(G, {node: encoded_movie})\n            G.nodes[encoded_movie]['title'] = encoded_movie\n            G.nodes[encoded_movie]['genres'] = genre_encoder.transform(data['genres']).tolist()\n            if 'tags' in data:\n                for tag_data in data['tags']:\n                    tag_data['tag'] = tag_encoder.transform([tag_data['tag']])[0]\n                    \n    encoded_users = [node for node, data in G.nodes(data=True) if data['bipartite'] == 0]\n    encoded_movies = [data['title'] for node, data in G.nodes(data=True) if data['bipartite'] == 1]\n    encoded_genres = [genre for node, data in G.nodes(data=True) if data['bipartite'] == 1 for genre in data['genres']]\n    encoded_tags = [tag_data['tag'] for node, data in G.nodes(data=True) if 'tags' in data for tag_data in data['tags']]\n\n    print(\"\\nEncoded Users:\", encoded_users[:5])  # Print first 5 encoded users\n    print(\"Encoded Movies:\", encoded_movies[:5])  # Print first 5 encoded movies\n    print(\"Encoded Genres:\", list(set(encoded_genres)))  # Print unique encoded genres\n    print(\"Encoded Tags:\", list(set(encoded_tags)))  # Print unique encoded tags\n\n    return G\nG_encoded = encode_graph(G)","metadata":{"execution":{"iopub.status.busy":"2023-10-06T15:42:46.243742Z","iopub.status.idle":"2023-10-06T15:42:46.244433Z","shell.execute_reply.started":"2023-10-06T15:42:46.244250Z","shell.execute_reply":"2023-10-06T15:42:46.244267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Convert the graph into PyG format\ndef convert_to_pyg_data(G):\n    # Extract edge indices\n    edge_index = torch.tensor(list(G.edges)).t().contiguous()\n    \n    # Extract node features (for simplicity, we'll use one-hot encoding for users and movies)\n    num_nodes = len(G.nodes)\n    x = torch.eye(num_nodes)\n    \n    # Extract edge features (ratings)\n    edge_attr = [G[u][v]['rating'] for u, v in G.edges]\n    edge_attr = torch.tensor(edge_attr).unsqueeze(-1).float()\n    \n    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n\ndata = convert_to_pyg_data(G_encoded)\n\n# 2. Define the GNN model\nclass BipartiteGNN(torch.nn.Module):\n    def __init__(self, num_node_features):\n        super(BipartiteGNN, self).__init__()\n        self.conv1 = GCNConv(num_node_features, 128)\n        self.conv2 = GCNConv(128, 64)\n        self.fc = torch.nn.Linear(64, 1)  # Predicting a single rating value\n\n    def forward(self, data):\n        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n        \n        # Node representation\n        x = self.conv1(x, edge_index, edge_attr)\n        x = F.relu(x)\n        x = self.conv2(x, edge_index, edge_attr)\n        x = F.relu(x)\n        \n        # Readout\n        x = global_add_pool(x, batch=data.batch)  # Aggregate node embeddings\n        out = self.fc(x)\n        return out\n\nmodel = BipartiteGNN(data.num_node_features)\n\n# 3. Training the model\n# For simplicity, we'll use Mean Squared Error (MSE) loss and Adam optimizer\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nprint(data)\n# Dummy training loop (you'll need to split your data into train and test)\nfor epoch in range(100):\n    model.train()\n    optimizer.zero_grad()\n    out = model(data)\n    loss = criterion(out, data.y)  # Assuming data.y contains the true ratings\n    loss.backward()\n    optimizer.step()\n    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-06T15:42:46.245158Z","iopub.status.idle":"2023-10-06T15:42:46.245450Z","shell.execute_reply.started":"2023-10-06T15:42:46.245307Z","shell.execute_reply":"2023-10-06T15:42:46.245321Z"},"trusted":true},"execution_count":null,"outputs":[]}]}